## <span style="color:red">**This project is coming soon! Please check back in a few days.**</span> ##

# AI Model Efficiency Toolkit
This project provides a library of advanced compression and quantization techniques for trained neural network models. It provides features that have been proven to improve run-time performance of deep learning neural network models with lower memory requirements and minimal impact to task accuracy.

- [Introduction](#introduction)
- [Installation and usage](#installation-and-usage)
- [Contributions](#contributions)
- [Team](#team)
- [License](#license)

## Introduction
AI Model Efficiency Toolkit (AIMET) is implemented as an extension to the [TensorFlow](https://www.tensorflow.org) and [PyTorch](https://pytorch.org) frameworks environment. Please visit https://quicinc.github.io/aimet-pages to learn more.

## Installation and usage
Visit the [USAGE.md](USAGE.md) file to obtain the build and installation instructions, user guide, example code and API documentation.

## Contributions
Thanks for your interest in contributing to the AIMET project! Please read our [Contributions page](CONTRIBUTING.md) for more information on contributing features or bug fixes. We look forward to your participation!

## Team
AIMET aims to be a community-driven project maintained by Qualcomm AI Research.

## License
AIMET is licensed under the BSD 3-clause “New” or “Revised” License, as found in the [LICENSE](LICENSE) file.
