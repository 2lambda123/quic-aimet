{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "attempted-child",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet18 model:\n",
      "\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "Initializing Datasets and Dataloaders...\n",
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "\n",
      "\n",
      "Normal fine-tuning of the model\n",
      "\n",
      "\n",
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 0.5740 Acc: 0.7172\n",
      "val Loss: 0.4463 Acc: 0.7843\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 0.3853 Acc: 0.8361\n",
      "val Loss: 0.2433 Acc: 0.9346\n",
      "\n",
      "Training complete in 0m 3s\n",
      "Best val Acc: 0.934641\n",
      "time taken for normal fine-tuning of the model 3.073135785991326\n",
      "\n",
      "\n",
      "Accuracy of fp32 model\n",
      "0.934641\n",
      "\n",
      "\n",
      "\n",
      "2021-04-01 15:55:21,805 - ConnectedGraph - WARNING - Ops with missing modules: ['flatten_67']\n",
      "This can be due to several reasons:\n",
      "1. There is no mapping for the op in ConnectedGraph.op_type_map. Add a mapping for ConnectedGraph to recognize and be able to map the op.\n",
      "2. The op is defined as a functional in the forward function, instead of as a class module. Redefine the op as a class module if possible. Else, check 3.\n",
      "3. This op is one that cannot be defined as a class module, but has not been added to ConnectedGraph.functional_ops. Add to continue.\n",
      "2021-04-01 15:55:21,809 - Quant - INFO - No config file provided, defaulting to config file at /local/mnt/workspace/rohanc/anaconda3/envs/aimet/lib/python3.6/site-packages/aimet_common/quantsim_config/default_config.json\n",
      "2021-04-01 15:55:21,818 - Utils - INFO - ...... subset to store [add_9, relu_10]\n",
      "2021-04-01 15:55:21,819 - Utils - INFO - ...... subset to store [add_16, relu_17]\n",
      "2021-04-01 15:55:21,819 - Utils - INFO - ...... subset to store [add_25, relu_26]\n",
      "2021-04-01 15:55:21,820 - Utils - INFO - ...... subset to store [add_32, relu_33]\n",
      "2021-04-01 15:55:21,820 - Utils - INFO - ...... subset to store [add_41, relu_42]\n",
      "2021-04-01 15:55:21,821 - Utils - INFO - ...... subset to store [add_48, relu_49]\n",
      "2021-04-01 15:55:21,821 - Utils - INFO - ...... subset to store [add_57, relu_58]\n",
      "2021-04-01 15:55:21,822 - Utils - INFO - ...... subset to store [add_64, relu_65]\n",
      "\n",
      "\n",
      "Accuracy of int8 model\n",
      "0.915033\n",
      "\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.3892 Acc: 0.8238\n",
      "val Loss: 0.2854 Acc: 0.9085\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.4133 Acc: 0.7992\n",
      "val Loss: 0.2719 Acc: 0.9281\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.3972 Acc: 0.7869\n",
      "val Loss: 0.2722 Acc: 0.9150\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.3349 Acc: 0.8484\n",
      "val Loss: 0.2909 Acc: 0.8824\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.3998 Acc: 0.7951\n",
      "val Loss: 0.2884 Acc: 0.8954\n",
      "\n",
      "Training complete in 1m 19s\n",
      "Best val Acc: 0.928105\n",
      "\n",
      "\n",
      "time taken for QAT 79.4771076219622\n",
      "\n",
      "\n",
      "Accuracy of quantized model after QAT\n",
      "0.928105\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Top level data directory. Here we assume the format of the directory conforms \n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"hymenoptera_data\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 5\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history\n",
    "\n",
    "\n",
    "\n",
    "def test_model(model, dataloaders, criterion, optimizer):\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['val']:\n",
    "        model.eval()   # Set model to evaluate mode\n",
    "        running_corrects = 0\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        accuracy = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "        return (format(accuracy, \".6f\"))\n",
    "#         print('Accuracy: {:4f}'.format(accuracy))\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "            \n",
    "            \n",
    "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    input_size = 224\n",
    "    \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print (\"Resnet18 model:\\n\")\n",
    "print(model_ft)\n",
    "\n",
    "\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "# Setup the loss fxn\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "from aimet_torch.quantsim import QuantizationSimModel\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "t1=time.perf_counter()\n",
    "\n",
    "print (\"\\n\")\n",
    "print (\"Normal fine-tuning of the model\")\n",
    "print (\"\\n\")\n",
    "# Normal model Training and evaluation\n",
    "\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=2)\n",
    "\n",
    "#set model to eval mode\n",
    "\n",
    "model_ft.eval()\n",
    "\n",
    "t2=time.perf_counter()\n",
    "\n",
    "\n",
    "print(\"time taken for normal fine-tuning of the model\", t2-t1)\n",
    "\n",
    "print (\"\\n\")\n",
    "print (\"Accuracy of fp32 model\")\n",
    "print (test_model(model_ft, dataloaders_dict, criterion, optimizer_ft))\n",
    "print (\"\\n\")\n",
    "\n",
    "ab=\"\"\n",
    "def forward_pass(model, iterations):\n",
    "    ab=test_model(model, dataloaders_dict, criterion, optimizer_ft)\n",
    "print (ab)\n",
    "    \n",
    "#Initialize the Quantization Simulator\n",
    "sim = QuantizationSimModel(model_ft, (1, 3, 224, 224))  \n",
    "\n",
    "# print (\"\\n\")\n",
    "# print (\"Simulated model:\\n\")\n",
    "# print (sim.model)\n",
    "# print (\"\\n\")\n",
    "\n",
    "#Compute the Quantization encodings\n",
    "sim.compute_encodings(forward_pass, forward_pass_callback_args=400)\n",
    "\n",
    "print (\"\\n\")\n",
    "print (\"Accuracy of int8 model\")\n",
    "print (test_model(sim.model, dataloaders_dict, criterion, optimizer_ft))\n",
    "print (\"\\n\")\n",
    "\n",
    "#set simulated model to train mode for Quatization aware training \n",
    "\n",
    "sim.model.train()\n",
    "\n",
    "# Quantization aware training\n",
    "\n",
    "t3=time.perf_counter()\n",
    "\n",
    "model_ft_1, hist = train_model(sim.model, dataloaders_dict, criterion, optimizer_ft, num_epochs=5)\n",
    "\n",
    "t4=time.perf_counter()\n",
    "\n",
    "print (\"\\n\")\n",
    "print(\"time taken for QAT\", t4-t3)\n",
    "sim.model.eval()\n",
    "print (\"\\n\")\n",
    "print (\"Accuracy of quantized model after QAT\")\n",
    "print (test_model(sim.model, dataloaders_dict, criterion, optimizer_ft))\n",
    "\n",
    "#save model\n",
    "sim.export(\"./model/\",\"quantized_model\", input_shape=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-halifax",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-promotion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
